{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. PREPARACIÓN DE DATOS\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv('articulos_ml.csv')\n",
    "\n",
    "# Limpieza: eliminar columnas no predictivas (texto/links) y nulos\n",
    "df_clean = df.drop(['Title', 'url'], axis=1).dropna()\n",
    "\n",
    "# Selección de features y target\n",
    "X = df_clean[['Word count', '# of Links', '# of comments', '# Images video', 'Elapsed days']]\n",
    "y = df_clean['# Shares']\n",
    "\n",
    "# Split 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. MODELO BASE (Sin Hiperparámetros)\n",
    "# ---------------------------------------------------------\n",
    "print(\"--- Evaluando Modelo Base (Default) ---\")\n",
    "base_rf = RandomForestRegressor(random_state=42) # Sin tunear nada\n",
    "base_rf.fit(X_train, y_train)\n",
    "y_pred_base = base_rf.predict(X_test)\n",
    "\n",
    "# Evaluación Base\n",
    "r2_base = r2_score(y_test, y_pred_base)\n",
    "rmse_base = np.sqrt(mean_squared_error(y_test, y_pred_base))\n",
    "print(f\"R2 Base: {r2_base:.4f}\")\n",
    "print(f\"RMSE Base: {rmse_base:.2f}\\n\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. OPTIMIZACIÓN (Búsqueda de Hiperparámetros)\n",
    "# ---------------------------------------------------------\n",
    "print(\"--- Iniciando Optimización (GridSearchCV) ---\")\n",
    "# Definimos la rejilla de parámetros a probar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=3, # Validación cruzada de 3 pliegues\n",
    "                           n_jobs=-1, # Usar todos los procesadores\n",
    "                           scoring='r2')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Mejores Hiperparámetros encontrados: {grid_search.best_params_}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. MODELO FINAL Y GRÁFICAS\n",
    "# ---------------------------------------------------------\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_opt = best_rf.predict(X_test)\n",
    "\n",
    "print(f\"R2 Optimizado: {r2_score(y_test, y_pred_opt):.4f}\")\n",
    "print(f\"RMSE Optimizado: {np.sqrt(mean_squared_error(y_test, y_pred_opt)):.2f}\")\n",
    "\n",
    "# Gráfica Comparativa: Real vs Predicho\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(y_test, y_pred_opt, alpha=0.5, color='green', label='Predicciones Optimizadas')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2, label='Perfecto')\n",
    "plt.xlabel('Valores Reales (Shares)')\n",
    "plt.ylabel('Predicciones (Shares)')\n",
    "plt.title('Regresión: Valores Reales vs Predichos (Random Forest Optimizado)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. PREPARACIÓN\n",
    "# ---------------------------------------------------------\n",
    "df_diabetes = pd.read_csv('diabetes.csv')\n",
    "X = df_diabetes.drop('Outcome', axis=1)\n",
    "y = df_diabetes['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. MODELO BASE (Default)\n",
    "# ---------------------------------------------------------\n",
    "print(\"--- Evaluando Modelo Base ---\")\n",
    "base_tree = DecisionTreeClassifier(random_state=42) # Crecerá hasta que las hojas sean puras\n",
    "base_tree.fit(X_train, y_train)\n",
    "y_pred_base = base_tree.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy Base: {accuracy_score(y_test, y_pred_base):.4f}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. OPTIMIZACIÓN\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n--- Buscando Hiperparámetros ---\")\n",
    "param_grid_tree = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 10, None], # Controlar profundidad es clave para evitar overfitting\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "                         param_grid=param_grid_tree,\n",
    "                         cv=5,\n",
    "                         scoring='accuracy')\n",
    "\n",
    "grid_tree.fit(X_train, y_train)\n",
    "print(f\"Mejores parámetros: {grid_tree.best_params_}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. RESULTADOS Y GRÁFICA\n",
    "# ---------------------------------------------------------\n",
    "best_tree = grid_tree.best_estimator_\n",
    "y_pred_opt = best_tree.predict(X_test)\n",
    "\n",
    "print(\"\\nReporte Clasificación Optimizado:\\n\", classification_report(y_test, y_pred_opt))\n",
    "\n",
    "# Gráfica del Árbol Optimizado\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(best_tree, feature_names=X.columns, class_names=['No Diabetes', 'Diabetes'], filled=True, rounded=True)\n",
    "plt.title(f'Árbol de Decisión Optimizado (Depth={best_tree.max_depth})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8298251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. PREPARACIÓN\n",
    "# ---------------------------------------------------------\n",
    "df_store = pd.read_csv('cliente_tienda.csv')\n",
    "# Usaremos Ingresos (col 3) y Puntuación Gastos (col 4)\n",
    "X_cluster = df_store.iloc[:, [3, 4]].values\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. MODELO INICIAL (K Arbitrario, ej: 3)\n",
    "# ---------------------------------------------------------\n",
    "print(\"--- Modelo Inicial (K=3) ---\")\n",
    "kmeans_base = KMeans(n_clusters=3, init='k-means++', random_state=42, n_init=10)\n",
    "labels_base = kmeans_base.fit_predict(X_cluster)\n",
    "print(f\"Inercia (WCSS) Base: {kmeans_base.inertia_:.2f}\")\n",
    "print(f\"Silhouette Score Base: {silhouette_score(X_cluster, labels_base):.4f}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. OPTIMIZACIÓN (Búsqueda del K óptimo - Método del Codo)\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n--- Optimizando (Buscando K óptimo) ---\")\n",
    "wcss = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for i in K_range:\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42, n_init=10)\n",
    "    kmeans.fit(X_cluster)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_cluster, kmeans.labels_))\n",
    "\n",
    "# Gráfica del Codo\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(K_range, wcss, marker='o')\n",
    "plt.title('Método del Codo')\n",
    "plt.xlabel('Número de Clusters (K)')\n",
    "plt.ylabel('WCSS (Inercia)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(K_range, silhouette_scores, marker='o', color='orange')\n",
    "plt.title('Silhouette Score')\n",
    "plt.xlabel('K')\n",
    "plt.show()\n",
    "\n",
    "print(\"Basado en el codo y silhouette, elegimos K=5\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. MODELO FINAL (K=5)\n",
    "# ---------------------------------------------------------\n",
    "kmeans_final = KMeans(n_clusters=5, init='k-means++', random_state=42, n_init=10)\n",
    "y_kmeans = kmeans_final.fit_predict(X_cluster)\n",
    "\n",
    "# Gráfica Final\n",
    "plt.figure(figsize=(8,6))\n",
    "colors = ['red', 'blue', 'green', 'cyan', 'magenta']\n",
    "for i in range(5):\n",
    "    plt.scatter(X_cluster[y_kmeans == i, 0], X_cluster[y_kmeans == i, 1], \n",
    "                s=100, c=colors[i], label=f'Cluster {i+1}')\n",
    "\n",
    "plt.scatter(kmeans_final.cluster_centers_[:, 0], kmeans_final.cluster_centers_[:, 1], \n",
    "            s=300, c='yellow', marker='*', label='Centroides')\n",
    "plt.title('Segmentación de Clientes (Modelo Optimizado)')\n",
    "plt.xlabel('Ingresos Anuales')\n",
    "plt.ylabel('Score de Gastos')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9781f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. PREPARACIÓN\n",
    "# ---------------------------------------------------------\n",
    "df_iris = pd.read_csv('Iris.csv')\n",
    "X_iris = df_iris.drop(['Id', 'species'], axis=1)\n",
    "y_iris = df_iris['species']\n",
    "\n",
    "# Estandarización (Obligatorio para PCA)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_iris)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. MODELO INICIAL (Full Components)\n",
    "# ---------------------------------------------------------\n",
    "# Iris tiene 4 features, así que creamos 4 componentes para evaluar\n",
    "pca_full = PCA(n_components=None) \n",
    "pca_full.fit(X_scaled)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. EVALUACIÓN Y SELECCIÓN (Optimización)\n",
    "# ---------------------------------------------------------\n",
    "variance_ratio = pca_full.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(variance_ratio)\n",
    "\n",
    "print(\"Varianza explicada por cada componente:\", variance_ratio)\n",
    "print(\"Varianza acumulada:\", cumulative_variance)\n",
    "\n",
    "# Gráfica de Varianza Acumulada para justificar la elección\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(1, len(cumulative_variance)+1), cumulative_variance, marker='o', linestyle='--')\n",
    "plt.axhline(y=0.95, color='r', linestyle='-', label='Umbral 95%')\n",
    "plt.title('Varianza Explicada Acumulada')\n",
    "plt.xlabel('Número de Componentes')\n",
    "plt.ylabel('Varianza Acumulada')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(\"Justificación: Con 2 componentes explicamos aprox el 95% de la información y permite visualización 2D.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. MODELO FINAL (Reducción a 2 componentes)\n",
    "# ---------------------------------------------------------\n",
    "pca_final = PCA(n_components=2)\n",
    "principalComponents = pca_final.fit_transform(X_scaled)\n",
    "\n",
    "# DataFrame Final para Graficar\n",
    "finalDf = pd.DataFrame(data=principalComponents, columns=['PC1', 'PC2'])\n",
    "finalDf = pd.concat([finalDf, df_iris[['species']]], axis=1)\n",
    "\n",
    "# Gráfica 2D\n",
    "plt.figure(figsize=(8,8))\n",
    "targets = df_iris['species'].unique()\n",
    "colors = ['r', 'g', 'b']\n",
    "for target, color in zip(targets, colors):\n",
    "    indices = finalDf['species'] == target\n",
    "    plt.scatter(finalDf.loc[indices, 'PC1'], finalDf.loc[indices, 'PC2'], c=color, s=50)\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.title('PCA Iris (Optimizado a 2 Componentes)')\n",
    "plt.legend(targets)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
